{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7134a257",
   "metadata": {},
   "source": [
    "## COSC274 Homework 4\n",
    "### Gibran Erlangga / F004QXJ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535cace",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a87413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7430.14</td>\n",
       "      <td>9529.78</td>\n",
       "      <td>-2453.33</td>\n",
       "      <td>19</td>\n",
       "      <td>123</td>\n",
       "      <td>621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11256.40</td>\n",
       "      <td>50455.10</td>\n",
       "      <td>-4220.00</td>\n",
       "      <td>18</td>\n",
       "      <td>216</td>\n",
       "      <td>2677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13093.00</td>\n",
       "      <td>51897.10</td>\n",
       "      <td>-2880.00</td>\n",
       "      <td>30</td>\n",
       "      <td>234</td>\n",
       "      <td>2464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14303.00</td>\n",
       "      <td>102632.00</td>\n",
       "      <td>-5702.20</td>\n",
       "      <td>144</td>\n",
       "      <td>281</td>\n",
       "      <td>4061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14688.00</td>\n",
       "      <td>83343.40</td>\n",
       "      <td>-2430.00</td>\n",
       "      <td>52</td>\n",
       "      <td>223</td>\n",
       "      <td>2822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  Label\n",
       "0    7430.14    9529.78   -2453.33         19        123        621      0\n",
       "1   11256.40   50455.10   -4220.00         18        216       2677      0\n",
       "2   13093.00   51897.10   -2880.00         30        234       2464      0\n",
       "3   14303.00  102632.00   -5702.20        144        281       4061      1\n",
       "4   14688.00   83343.40   -2430.00         52        223       2822      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('hw4_naive.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355607a",
   "metadata": {},
   "source": [
    "1) (5 points) Divide the data into test / train sets (80% and 20% respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d122c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since its tricky to implement multinomial NB on continuous data, I will convert the continuous data into bins\n",
    "target = 'Label'\n",
    "y = df[target]\n",
    "x = df.drop(target, axis=1)\n",
    "\n",
    "x_bins = pd.DataFrame()\n",
    "n_bin = 5\n",
    "\n",
    "for i in x:\n",
    "    new_col_name = i + \"_binned\"\n",
    "    x_bins[new_col_name] = pd.qcut(x[i], q=n_bin, labels=[i+1 for i in range(n_bin)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f0a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train-test split after binning\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_bins, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ac5c3",
   "metadata": {},
   "source": [
    "2) (25 points) Implement a Multinomial Naïve Bayes classifier **from scratch**, with smoothing (you can set the default smoothing value to 1). You are free to code this up however you like, however, make sure that there is a function that can be called with a test X vector and returns the predicted Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63e05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNB_scratch:\n",
    "    \n",
    "    def fit(self, x, y, smoothing_value = 1):\n",
    "        n_row, n_col = x.shape\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        # get max number of categories of all available features\n",
    "        n_cat = max([x_bins[i].nunique() for i in x_bins])\n",
    "        \n",
    "        self.features_proba = np.zeros((n_classes, n_cat, n_col), dtype=np.float64)\n",
    "        self.prior = np.zeros(n_classes, dtype=np.float64)\n",
    "        \n",
    "        for c in self.classes:\n",
    "            x_c = x[y == c]\n",
    "            # calculate prior\n",
    "            self.prior[c] = len(x_c)/ len(x)\n",
    "            # calculate likelihood\n",
    "            for idx, var in enumerate(x_c):\n",
    "                self.features_proba[c, :, idx] = x_c[var].value_counts(normalize=True).sort_index()\n",
    "        \n",
    "        # apply smoothing to avoid the zero problem, using laplace (alpha = 1) or lidstone (alpha < 1) smoothing\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y_pred = [self._predict(i) for i in x.to_numpy()]\n",
    "        return y_pred\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        posteriors = []\n",
    "        \n",
    "        for idx, c in enumerate(self.classes):\n",
    "            posterior_c = self.prior[idx] * self._features_proba(idx, x)\n",
    "            posteriors.append(posterior_c)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "    \n",
    "    def _features_proba(self, class_idx, x):\n",
    "        var_proba = []\n",
    "        \n",
    "        for idx, val in enumerate(x):\n",
    "            proba = self.features_proba[class_idx, val-1, idx]\n",
    "            var_proba.append(proba)\n",
    "        \n",
    "        return np.prod(var_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae70633",
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomNB = MultinomialNB_scratch()\n",
    "multinomNB.fit(x_train, y_train, smoothing_value=1)\n",
    "y_pred_multi = multinomNB.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d04f10f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92cc1ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gibranerlangga/opt/miniconda3/envs/cosc274/lib/python3.9/site-packages/sklearn/utils/validation.py:964: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(\n",
      "/Users/gibranerlangga/opt/miniconda3/envs/cosc274/lib/python3.9/site-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred_multi_sklearn = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9955cadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_multi_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617a5984",
   "metadata": {},
   "source": [
    "3) (25 points) Implement a Gaussian Naïve Bayes classier **from scratch** (no need for smoothing here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d196cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Label'\n",
    "y = df[target]\n",
    "x = df.drop(target, axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eaad775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian naive bayes classifier\n",
    "class GaussianNB_scratch:\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        n_row, n_col = x.shape\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        self.mean = np.zeros((n_classes, n_col), dtype=np.float64)\n",
    "        self.std = np.zeros((n_classes, n_col), dtype=np.float64)\n",
    "        self.prior = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "#         for num, c in enumerate(self.classes):\n",
    "        for c in self.classes:\n",
    "            x_class = x[y == c]\n",
    "            self.mean[c,:] = x_class.mean()\n",
    "            self.std[c,:] = x_class.std()\n",
    "            self.prior[c] = len(x_class)/ len(x)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        y_pred = [self._predict(i) for i in x.to_numpy()]\n",
    "        return y_pred\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        posteriors = []\n",
    "        \n",
    "        for idx, c in enumerate(self.classes):\n",
    "            # apply log to avoid floating point errors\n",
    "            prior_c = np.log(self.prior[idx])\n",
    "            class_cond_c = np.sum(np.log(self._pdf(idx, x)))\n",
    "            posterior_c = class_cond_c + prior_c\n",
    "            posteriors.append(posterior_c)\n",
    "            \n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "            \n",
    "    def _pdf(self, class_idx, x):\n",
    "        mean = self.mean[class_idx]\n",
    "        std = self.std[class_idx]\n",
    "        numerator = np.exp(-1*(x-mean)**2 / (2*std**2))\n",
    "        denominator = np.sqrt(2*np.pi*std**2)\n",
    "        return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5be32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation using sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian_nb = GaussianNB_scratch()\n",
    "gaussian_nb.fit(x_train, y_train)\n",
    "y_pred_gauss = gaussian_nb.predict(x_test)\n",
    "\n",
    "gaussian_nb_sklearn = GaussianNB()\n",
    "gaussian_nb_sklearn.fit(x_train, y_train)\n",
    "y_pred_gauss_sklearn = gaussian_nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a2c2dc",
   "metadata": {},
   "source": [
    "4) (10 points) Calculate the accuracy and the F1 score of test data using both of your models implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3192c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "0.5178571428571429 0.5196428571428572\n",
      "0.3430656934306569 0.3685446009389671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "accuracy_scratch = accuracy_score(y_test, y_pred_multi)\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_multi_sklearn)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_multi)\n",
    "f1_sklearn = f1_score(y_test, y_pred_multi_sklearn)\n",
    "\n",
    "print('Multinomial Naive Bayes')\n",
    "print(accuracy_scratch, accuracy_sklearn)\n",
    "print(f1, f1_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4def4538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes\n",
      "0.5955357142857143 0.5955357142857143\n",
      "0.3020030816640986 0.3020030816640986\n"
     ]
    }
   ],
   "source": [
    "accuracy_scratch = accuracy_score(y_test, y_pred_gauss)\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_gauss_sklearn)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_gauss)\n",
    "f1_sklearn = f1_score(y_test, y_pred_gauss_sklearn)\n",
    "\n",
    "print('Gaussian Naive Bayes')\n",
    "print(accuracy_scratch, accuracy_sklearn)\n",
    "print(f1, f1_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8baafd",
   "metadata": {},
   "source": [
    "### Bonus: K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07513f07",
   "metadata": {},
   "source": [
    "1) (35 points) Implement a generalized K-means/median algorithm. You should have a single function that takes in as input the data points, K, and some other hyperparameters, specified below. The function should return K sets of data points. Each set corresponding to one cluster.\n",
    "\n",
    "The hyperparameters your functions should support and the values they can take are:\n",
    "- The method for calculating the centroid: Means or Median\n",
    "- The initialization method: Random Split Initialization or Random Seed Selection Method\n",
    "- Max_iter: max number of iterations to run the algorithm. \n",
    "- K: number of clusters\n",
    "\n",
    "Note that your stopping condition should have two parts: \n",
    "- stop if you reach the max iterations\n",
    "- stop if no change is made to the clusters in the last step.\n",
    "\n",
    "You will be running this code in question 3 of the assignment. For this part you just need to implement the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d067eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.201517</td>\n",
       "      <td>-0.683358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.374519</td>\n",
       "      <td>-0.828082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.161895</td>\n",
       "      <td>-1.247107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2\n",
       "0 -0.201517 -0.683358\n",
       "1  0.374519 -0.828082\n",
       "2 -0.161895 -1.247107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "df_cluster = pd.read_csv('hw4_cluster.csv')\n",
    "df_cluster.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dadc8d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd5b87bbd90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df_cluster.x1, df_cluster.x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e988d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize cluster centers\n",
    "def k_means(data, k, method, init_method, max_iter):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1758a90",
   "metadata": {},
   "source": [
    "2) (15 points) SSE score.\n",
    "In this part of the assignment, you are implementing a function that calculates the SSE for a list of clusters. The function should take in a list of clusters (such as the output of the last function you implemented) and return a single SSE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a1823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cffa20fe",
   "metadata": {},
   "source": [
    "3) (15 points) Finding best K.\n",
    "\n",
    "Run the code you implemented in question 1 for k=2,3,4,5. Set the other hyperparameters to the following:\n",
    "- The method for calculating the centroid: Mean\n",
    "- The initialization method: Random Split Initialization \n",
    "- Max_iterations: 100\n",
    "\n",
    "Calculate the SSE for each K using the function in question 2 and use these scores to pick the best K. What is the best K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4903234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
