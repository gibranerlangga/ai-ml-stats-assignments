---
title: "qbs124_hw3_gibran"
author: "Gibran Erlangga"
date: "4/16/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1
(10 points). Referring to the R function cdf.dyn the cost of overlooking a patient with high blood pressure that may lead to a stroke is \$50K and the cost of wrong decision on the high risk health situations is \$25K. Use the binormal curve to find the optimal decision on the threshold that minimizes the cost. Display the binormal ROC and the vertical and horizontal lines for the implied optimal false positive and sensitivity rates. Display axis(side=3) to show the threshold values.

``` {r}
# plot binormal ROC
# do log-transformation, show the actual value at the optimal value on the plot
# import data and set-up

n=100
X=exp(rnorm(n,mean=1,sd=.1))*75
Y=exp(rnorm(1.5*n,mean=.9,sd=.08))*75
nY=rep(0,1.5*n)
nX = rep(1, n)

X_data = data.frame(cbind(nX, X))
names(X_data) = c('n', 'val')
Y_data = data.frame(cbind(nY, Y))
names(Y_data) = c('n', 'val')

data <- rbind(X_data, Y_data)
a = data$n
b = data$val

par(mfrow = c(1, 1), mar = c(4.5, 4.5, 3, 1), cex.main = 1.5, cex.lab = 1.5)
n = length(a)
ind = rep(0, n)
ind[a == 0] = 1
XY = data$val
ind = ind[order(XY)]
XY = XY[order(XY)]
sens = comp.spec = rep(0, n)
AUC = 0

for (i in 1:n) {
sens[i] = sum(XY < XY[i] & ind == 1)/sum(ind == 1)
comp.spec[i] = sum(XY < XY[i] & ind == 0)/sum(ind == 0)
if (i > 1)
AUC = AUC + sens[i] * (comp.spec[i] - comp.spec[i - 1])
}
plot(comp.spec, sens, type = "s", xlim = c(0, 1), ylim = c(0, 1), xlab = "False positive (1-specificity)",
ylab = "Sensitivity", lwd = 2, main = "ROC curve for identification of Strokes")
segments(-1, -1, 2, 2, col = 2)
text(0.8, 0.5, paste("AUC = ", round(AUC * 100), "%", sep = ""), cex = 1.75,
font = 2)
a = abs(sens - 0.8)

c.8 = mean(comp.spec[a == min(a)])
lines(x = c(-1, c.8, c.8), y = c(0.8, 0.8, -2), col = 3, lwd = 2)
text(0.7, 0.2, paste("TP =", 0.8, "\nFN =", 1 - 0.8, "\nFP =", round(c.8, 2), "\nTN =", 1 - round(c.8, 2)), cex = 1, adj = 0)
th.8 = 10**mean(XY[a == min(a)])
print(paste("FP.8=", c.8, " Th.8=", th.8, "thousand dollars"))
tot.cost = rep(NA, n)
for (i in 1:n) {
sens[i] = sum(XY < XY[i] & ind == 1)/sum(ind == 1)
comp.spec[i] = sum(XY < XY[i] & ind == 0)/sum(ind == 0)
tot.cost[i] = 50 * (1 - sens[i]) + 25 * comp.spec[i]
}
iopt = which(tot.cost == min(tot.cost))
opt.inc = XY[iopt]
print(paste("Optimal threshold =", opt.inc))
segments(comp.spec[iopt], -1, comp.spec[iopt], 2, lwd = 2)
text(comp.spec[iopt] + 0.03, 0.3, paste("Optimal threshold =", opt.inc, "",
sep = ""), srt = 90, cex = 1, font = 3)
```

## Question 2
2. (10 points). Using the data set HeightWeight.csv for 25,000 Korean teenagers estimate the weight of an individual with height 70 inches. Display the scatterplot and the prediction along with the $±1.96_{y|x}$ interval using the sample estimates from the Normal regression section (no lm function).
``` {r}
# import data
hw_data <- read.csv('HeightWeight.csv')
head(hw_data)

# in this case, Y = weight, X = height, with x = 70 inches
cond_mean <- function(y, X, x) {
  mean_X = mean(X)
  std_X = sqrt(var(X))
  mean_y = mean(y)
  std_y = sqrt(var(y))
  corr_coef = cor(y, X)
  return (mean_y + corr_coef*(std_y/std_X)*(x-mean_X))
}

estimated_weight = cond_mean(hw_data$Weight.Pounds., hw_data$Height.Inches., 70)
estimated_weight_1above = cond_mean(hw_data$Weight.Pounds., hw_data$Height.Inches., 71)
slope=(estimated_weight_1above-estimated_weight)/1
estimated_inter = cond_mean(hw_data$Weight.Pounds., hw_data$Height.Inches., 0)
RO=cor(hw_data$Weight.Pounds., hw_data$Height.Inches.)
a<-sqrt((1-RO)*(sd(hw_data$Weight.Pounds.)^2))
b<-a*1.96
upper<-(estimated_inter+b)
lower<-(estimated_inter-b)

paste('Estimated weight of Korean individual with height of 70 inches is', round(estimated_weight, 3), 'pounds.')

plot(hw_data$Height.Inches., hw_data$Weight.Pounds.,
     xlab = 'Height (inches)',
     ylab = 'Weight (pounds)',
     main = 'Scatter Plot of Height and Weight along with prediction line')

# linear prediction line
abline(estimated_inter,slope, col = "blue")

# confidence interval
abline(upper,slope, col = "green", lty=2)
abline(lower,slope, col = "green", lty=2)
points(70, estimated_weight, pch=19, col=2)
legend('topleft', 
       c('Confidence interval', 'Prediction line', 
         'Estimated weight at height = 70 inches'),
       bg='gray92',
       lty=c(2, 1, NA),
       pch=c(NA, NA, 19),
       col=c('pink', 'blue', 2),
       cex=0.6
       )
```

## Question 3
(5 points). Correct the wrong conclusion on improving the revenue by hiring more truck drives by running a linear regression of revenue on time and the number of truck drivers. Explain why it helps.

**Answer:**
The i.i.d assumption does not get valid as we have value that grows over time. As we have value growing time we use the formula coefficient of termination in regression $R^2=1-\frac{\sum x_i^2}{\sum(y_i-\overline y)^2}$ and $\sum x_i^2$ as numerator, is the vertical distance square, while in the denominator, which is so initally there was a huge variance which is not the variance of y as y grows in time, so here the denominator increases and $R^{2}$ approaching 1.

To fix this problem, x and y has to be i.i.d or fluctuating from the mean of value. Therefore, we can exclude time from the analysis. I computed the trend and revenue as the function of time and take residuals, take difference between revenue and trend, and same for truck drivers and then correlate both the residuals. The correlation coefficient is positive, and also the coefficient of termination is 0.067.

``` {r}
# import data
truck_data <- read.csv('truckR.data.csv')
truck_data$driver_id = 1:nrow(truck_data)
head(truck_data)

# linear regression on revenue given time
model_rev_time_residuals = lm(truc.dr ~ driver_id,data=truck_data)$residuals
# linear regression on revenue given number of truck drivers
model_rev_driver_residuals = lm(revenue ~ driver_id,data=truck_data)$residuals

plot(model_rev_time_residuals, model_rev_driver_residuals, cex=1, pch=19)
abline(lsfit(x=model_rev_time_residuals,y=model_rev_driver_residuals),lwd=3)
mtext(side=1,"Truck residuals",cex=1.25,line=2.5)
mtext(side=2,"Revenue residuals",cex=1.25,line=2.5)
r2=cor(model_rev_time_residuals,model_rev_driver_residuals)**2
text(-1,6,paste("R-squared =",round(r2,3)),adj=0,font=2,cex=1.5)
```

## Question 4
(5 points). Provide possible explanation for the negative sign at Nose despite its positive correlation with Height.
``` {r}
da=read.csv("HeightFootNose.csv")
par(mfrow=c(1,3),mar=c(3.5,3.5,3,1))

# foot vs height
plot(da$Foot,da$Height,xlab="",ylab="")
title(paste("Height versus length of foot, R =",round(cor(da$Foot,da$Height),2)))
mtext(side=1,"Foot, inches",cex=1.25,line=2.5)
mtext(side=2,"Height, inches",cex=1.25,line=2.25)
print(summary(lm(Height~Foot,data=da)))
abline(lsfit(x=da$Foot,y=da$Height),lwd=3)

# nose vs height
plot(da$Nose,da$Height,xlab="",ylab="")
title(paste("Height versus length of nose, R =",round(cor(da$Nose,da$Height),2)))
mtext(side=1,"Nose, inches",cex=1.25,line=2.5)
mtext(side=2,"Height, inches",cex=1.25,line=2.25)
print(summary(lm(Height~Nose,data=da)))
abline(lsfit(x=da$Nose,y=da$Height),lwd=3)

# nose vs foot
plot(da$Nose,da$Foot,xlab="",ylab="")
title(paste("Height versus length of nose, R =",round(cor(da$Nose,da$Foot),2)))
mtext(side=1,"Foot, inches",cex=1.25,line=2.5)
mtext(side=2,"Nose, inches",cex=1.25,line=2.25)
print(summary(lm(Nose~Foot,data=da)))
abline(lsfit(x=da$Nose,y=da$Foot),lwd=3)

# set foot and nose as predictors and height as dependent variable
print(summary(lm(Height~Foot+Nose,data=da)))
print(c(sd(da$Height),sd(da$Foot),sd(da$Nose)))

f=da$Foot-mean(da$Foot)
n=da$Nose-mean(da$Nose)
h=da$Height
print(summary(lm(h~f+n,data=da)))
```

**Answer:**
The graphics above show the relationship between Foot vs Height, Nose vs Height and Foot vs Nose (as independent vs dependent variable). We can observe that when we set foot as constant, tall people have shorter nose or taller, like with respect of the foot size of them all being same, that is constant.

## Question 5
(10 points). Display the time watching of alcohol scenes as a function of age for a black girl who drinks, has an alcohol related item, with high income and high parents’ education, and has good grades as in function kidsdrink(job=2). To contrast, display the same girl but who does not drink and does not have an alcohol related item. Compute and display the the effect of drinking and having an alcohol related item.
``` {r}
kidsdrink_data <-read.csv("kidsdrink.csv")

d<-kidsdrink_data
d=cbind(d,log(1/60^2+d$alcm))
	names(d)[ncol(d)]="logalcm"
	o=lm(logalcm~drink+age+boy+race+alcbr+pared+inc+grade,data=d)
	print(summary(o))
	par(mfrow=c(1,1),mar=c(4.5,4.5,1,1),cex.lab=1.5)
	alab=c(1,2,5,10,25,50);lalab=log(alab)
	plot(d$age,d$logalcm,xlim=c(12,17),ylim=range(lalab),type="n",
	     axes=F,xlab="Age",ylab="Alcohol scene watching")
	axis(side=1,12:16)
	axis(side=2,at=lalab,labels=paste(alab,"h"),srt=90)
	for(a in 12:16)
	{
		da=d$logalcm[d$age==a];n=length(da)
		points(rep(a,n),da)
		den=density(da,from=0)
		lines(a+1.25*den$y,den$x)	
	}
	x=11:16
	a=coef(o)
	
	lines(x,a[1]+a[2]+a[3]*x+a[6]+a[7]+a[8],col=2,lwd=3)
	lines(x,a[1]+a[3]*x+a[7]+a[8],col=3,lwd=3,lty=2)
	legend(14,log(2),c("Black girl who drinks and has an alcohol-related item",
	                     "Black girl who does not drink and do not own an alcohol-related item"),col=2:3,lwd=3,lty=1:2,bg="gray97",cex=0.5)
```